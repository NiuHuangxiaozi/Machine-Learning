{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fa4a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.datasets as da\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "from tqdm import *\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb32a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerDataset:\n",
    "    def __init__(self,dir_path,train_batch=32,test_batch=15):\n",
    "        self.dir_path=dir_path\n",
    "        self.train_batch_size = train_batch\n",
    "        self.test_batch_size = test_batch\n",
    "        self.classification={\n",
    "            \"daisy\":0,\n",
    "            \"roses\":1,\n",
    "            \"sunflowers\":2,\n",
    "            \"tulips\":3\n",
    "        }\n",
    "        \n",
    "        self.train_size=None\n",
    "        self.test_size=None\n",
    "        \n",
    "    def process_data(self):\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        augs = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.RandomResizedCrop(size=224),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        train_set=da.ImageFolder(self.dir_path+\"/flower_photos\",transform=augs)\n",
    "        test_set=da.ImageFolder(self.dir_path+\"/flower_test_photos\",transform=augs)\n",
    "        \n",
    "        self.train_size=len(train_set)\n",
    "        self.test_size=len(test_set)\n",
    "        train_iter = Data.DataLoader(train_set, batch_size=self.train_batch_size, shuffle=True)\n",
    "        test_iter=Data.DataLoader(test_set,batch_size=self.test_batch_size,shuffle=True)\n",
    "        \n",
    "        return train_iter,test_iter\n",
    "    \n",
    "    def Get_data_size(self):\n",
    "        return self.train_size , self.test_size\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c436e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleM(nn.Module):\n",
    "    def __init__(self):\n",
    "            super(SimpleM,self).__init__()\n",
    "            \n",
    "            self.conv1=nn.Conv2d(in_channels=3,out_channels=12,padding=1,kernel_size=3)\n",
    "            self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "            self.relu1=nn.ReLU()\n",
    "            \n",
    "            self.conv2=nn.Conv2d(in_channels=12,out_channels=12,padding=1,kernel_size=3)\n",
    "            self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "            self.relu2=nn.ReLU()\n",
    "            \n",
    "            self.conv3=nn.Conv2d(in_channels=12,out_channels=12,padding=1,kernel_size=3)\n",
    "            self.maxpool3=nn.MaxPool2d(kernel_size=2)\n",
    "            self.relu3=nn.ReLU()\n",
    "            \n",
    "            self.linear=nn.Linear(in_features=12*28*28,out_features=4)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.maxpool1(x)\n",
    "        x=self.relu1(x)\n",
    "        \n",
    "    \n",
    "        x=self.conv2(x)\n",
    "        x=self.maxpool2(x)\n",
    "        x=self.relu2(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.maxpool3(x)\n",
    "        x=self.relu3(x)\n",
    "        \n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=self.linear(x)\n",
    "        x=F.softmax(x,dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d742717b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/10] TEST: average_loss 0.07334174 Total_acc 0.65000004: 100%|██████████| 85/85 [00:20<00:00,  4.14it/s]\n",
      "[2/10] TEST: average_loss 0.07570726 Total_acc 0.60000002: 100%|██████████| 85/85 [00:11<00:00,  7.24it/s]\n",
      "[3/10] TEST: average_loss 0.06881366 Total_acc 0.73333335: 100%|██████████| 85/85 [00:11<00:00,  7.33it/s]\n",
      "[4/10] TEST: average_loss 0.07051913 Total_acc 0.66666669: 100%|██████████| 85/85 [00:11<00:00,  7.19it/s]\n",
      "[5/10] TEST: average_loss 0.07200361 Total_acc 0.65000004: 100%|██████████| 85/85 [00:12<00:00,  6.95it/s]\n",
      "[6/10] TEST: average_loss 0.06676466 Total_acc 0.75000006: 100%|██████████| 85/85 [00:12<00:00,  7.02it/s]\n",
      "[7/10] TEST: average_loss 0.06801752 Total_acc 0.73333335: 100%|██████████| 85/85 [00:12<00:00,  7.01it/s]\n",
      "[8/10] TEST: average_loss 0.06874962 Total_acc 0.68333340: 100%|██████████| 85/85 [00:12<00:00,  6.99it/s]\n",
      "[9/10] TEST: average_loss 0.06909140 Total_acc 0.68333340: 100%|██████████| 85/85 [00:12<00:00,  6.97it/s]\n",
      "[10/10] TEST: average_loss 0.06412002 Total_acc 0.76666671: 100%|██████████| 85/85 [00:10<00:00,  7.97it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    #设备\n",
    "    device='cuda:0'if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    dataset=FlowerDataset(os.getcwd())\n",
    "    train_loader,test_loader=dataset.process_data()\n",
    "    train_length,test_length=dataset.Get_data_size()\n",
    "    #定义模型\n",
    "    model=SimpleM()\n",
    "    model=model.to(device)\n",
    "    \n",
    "    \n",
    "    #定义损失函数\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #定义优化器，梯度更新规则\n",
    "    optim=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    #我们一共训练10轮\n",
    "    Epoch=10\n",
    "\n",
    "    #history记录test阶段的loss和accurary用于画图\n",
    "    history = {'Test Loss':[],'Test Accuracy':[]}\n",
    "\n",
    "\n",
    "    for epoch in range(1,Epoch+1):\n",
    "        #训练部分\n",
    "        '''\n",
    "            这个写法可以生成进度条，enumerrate会生成（index，value)的组合对\n",
    "            trainloader对象本来就是（data，label）的组合对\n",
    "        '''\n",
    "        processBar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        \n",
    "        #模型训练之前一定要写\n",
    "        model.train()\n",
    "\n",
    "        \n",
    "        for index,(data,label) in processBar:\n",
    "            '''\n",
    "               data的形状: [B,3,224,224]\n",
    "            '''\n",
    "            data=data.to(device)\n",
    "            label=label.to(device)\n",
    "\n",
    "            #模型前向传播\n",
    "            outputs=model(data)\n",
    "\n",
    "            #argmax就是按照某一个维度求得这个维度上最大值的下标，如果不想降维，请使用keepdim=True\n",
    "            prediction=torch.argmax(outputs,dim=1)\n",
    "            \n",
    "            #sum(prediction==label)会生成0-1矩阵，sum求和就是统计为True的过程，再除以本次batch的数量\n",
    "            acc=torch.sum(prediction==label)/data.shape[0]\n",
    "\n",
    "            #计算损失\n",
    "            loss=loss_func(outputs,label)\n",
    "\n",
    "            '''\n",
    "            反向传播三件套\n",
    "                zero_grad可以将上一次计算得出的梯度清零，因为每次梯度的计算使用的是加法，如果不清0，那么后面梯度的更新就会加入前面计算出来的梯度\n",
    "                backward反向传播\n",
    "                step更新参数\n",
    "            '''\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            #进度条旁边打印说明\n",
    "            processBar.set_description(\"[%d/%d] Loss : %.8f Acc：%.8f\" %(epoch,Epoch,loss,acc))\n",
    "\n",
    "            #在最后一轮训练完了以后进行测试\n",
    "            if index==len(processBar)-1:\n",
    "                #模型在测试之前要加eval，避免好像drop和normalize的影响\n",
    "                model.eval()\n",
    "                '''\n",
    "                    with torch.no_grad()这句话一定要加，很节省显存空间，测试阶段不用计算任何梯度。\n",
    "                '''\n",
    "                with torch.no_grad():\n",
    "                    total_loss=0.\n",
    "                    total_right=0\n",
    "                    for index,(t_data,t_label) in enumerate(test_loader):\n",
    "\n",
    "                        #以下这些和训练的时候一样，可以看上面的训练\n",
    "                        t_data=t_data.to(device)\n",
    "                        t_label=t_label.to(device)\n",
    "\n",
    "                        t_outputs=model(t_data)\n",
    "\n",
    "                        loss=loss_func(t_outputs,t_label)\n",
    "                        t_prediction=torch.argmax(t_outputs,dim=1)\n",
    "\n",
    "                        total_loss+=loss\n",
    "                        total_right+=torch.sum(t_prediction==t_label)\n",
    "                    average_loss=total_loss/test_length\n",
    "                    total_acc=total_right/test_length\n",
    "                    #print(average_loss.item())\n",
    "                    history['Test Loss'].append(average_loss.item())\n",
    "                    history['Test Accuracy'].append(total_acc.item())\n",
    "                    processBar.set_description(\"[%d/%d] TEST: average_loss %.8f Total_acc %.8f\" %(epoch,Epoch,average_loss,total_acc))\n",
    "            \n",
    "            \n",
    "        processBar.close()     \n",
    "        torch.save(model.state_dict(),\"SimpleM.pt\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83e01fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SimpleM'>\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch_model=SimpleM()  # 由研究员提供python.py文件\n",
    "torch_model.load_state_dict(torch.load(os.getcwd()+\"/SimpleM.pt\"))\n",
    "print(type(torch_model))\n",
    "batch_size = 1         # 批处理大小\n",
    "input_shape = (3, 224, 224) # 输入数据\n",
    " \n",
    "# set the model to inference mode\n",
    "torch_model.eval()\n",
    " \n",
    "x = torch.randn(batch_size,*input_shape) # 生成张量\n",
    "export_onnx_file = \"SimpleM.onnx\"        # 目的ONNX文件名\n",
    "torch.onnx.export(torch_model,\n",
    "                    x,\n",
    "                    export_onnx_file,\n",
    "                    opset_version=10,\n",
    "                    do_constant_folding=True,# 是否执行常量折叠优化\n",
    "                    input_names=[\"input_shape\"],# 输入名\n",
    "                    output_names=[\"output\"]# 输出名\n",
    "                    )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfc8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
